{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09a8697",
   "metadata": {},
   "source": [
    "# Learn Train object\n",
    "### *Narges Rezaie*\n",
    "#### Vignette built on Apr 1, 2023 with Topyfic version 0.2.0.\n",
    "\n",
    "The aim of this tutorials is show you how you can train your data faster!\n",
    "\n",
    "The most time-consuming part is learning train object. In order to get the trian object faster, you can tune the parameters like number of jobs or number of threads, however if your data is big it's going to spend some time to copy your data. One other way is to submit job simolotinalsy in order to get your train object faster to have one train object per random state and then use `combine_LDA_models()` function to have one train object.\n",
    "\n",
    "Below you can find the script about how you can make and submit jobs.\n",
    "\n",
    "**note**: Don't forget to modify the script base on the machine you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ada3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "#SBATCH -A SEYEDAM_LAB\n",
    "#SBATCH --cpus-per-task 1\n",
    "#SBATCH --output=LDAs.out\n",
    "#SBATCH --error=LDAs.err\n",
    "#SBATCH --time=1:00:00\n",
    "#SBATCH -J topyfic_control\n",
    "#SBATCH --mail-type=START,END\n",
    "#SBATCH --partition=standard\n",
    "\n",
    "data=../../data/all_ModelAD_ENCODE_5xFAD_final.h5ad\n",
    "\n",
    "for i in {0..99}\n",
    "do\n",
    "    scriptName=run_${i}\n",
    "    curr=${scriptName}.sh\n",
    "    echo '#!/bin/bash' > ${curr}\n",
    "    echo '#SBATCH -A SEYEDAM_LAB' >> ${curr}\n",
    "    echo '#SBATCH --cpus-per-task 10' >> ${curr}\n",
    "    echo '#SBATCH --output=LDA-%J.out' >> ${curr}\n",
    "    echo '#SBATCH --error=LDA-%J.err' >> ${curr}\n",
    "    echo '#SBATCH --time=02:00:00' >> ${curr}\n",
    "    echo '#SBATCH -J topyfic-control-%J' >> ${curr}\n",
    "    echo '#SBATCH --mail-type=START,END' >> ${curr}\n",
    "    echo '#SBATCH --partition=standard' >> ${curr}\n",
    "    \n",
    "    echo \"python3 topyfic_train.py ${data} 5 ${i}\" >> ${curr}\n",
    "    \n",
    "    chmod +x ${curr}\n",
    "    sbatch ${scriptName}.sh\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21052f21",
   "metadata": {},
   "source": [
    "### topyfic_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3f8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import Topyfic\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#input\n",
    "path = str(sys.argv[1])\n",
    "k = int(sys.argv[2])\n",
    "random_state = int(sys.argv[3])\n",
    "\n",
    "data = sc.read_h5ad(path)\n",
    "\n",
    "\n",
    "train = Topyfic.Train(name=f\"train_{k}_{random_state}\",\n",
    "                      k=k,\n",
    "                      n_runs=1,\n",
    "                      random_state_range=[random_state])\n",
    "\n",
    "train.run_LDA_models(data, batch_size=128, max_iter=5, n_jobs=1, n_thread=1)\n",
    "\n",
    "train.save_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f0d8b",
   "metadata": {},
   "source": [
    "### combine all singe LDA runs\n",
    "\n",
    "one you have all your train runs with one random seed, you can follow the code bellow to make train objects contain all runs you want\n",
    "\n",
    "**note**: don't forget to modify `k` and `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b132f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Topyfic\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "k = 5\n",
    "path = \"../../data/all_ModelAD_ENCODE_final.h5ad\"\n",
    "\n",
    "data = sc.read_h5ad(path)\n",
    "\n",
    "main_train = Topyfic.Train(name=f\"train_{k}\",\n",
    "                           k=k,\n",
    "                           n_runs=100)\n",
    "trains = []\n",
    "for i in range(100):\n",
    "    train = Topyfic.read_train(f\"train_{k}_{i}.p\")\n",
    "    trains.append(train)\n",
    "    \n",
    "main_train.combine_LDA_models(data, single_trains=trains)\n",
    "main_train.save_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da263bf",
   "metadata": {},
   "source": [
    "once you hace your train model, you can follow other tutorials for building top model and downstream analysis.\n",
    "\n",
    "***if you need more infor about the inputs of each functions look at the API documentation [here](https://mortazavilab.github.io/Topyfic/html/api.html).***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
